{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TariqHusainKhan/30-Days-Of-JavaScript/blob/master/Copy_of_Group_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpYEzD5j8Yrv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (convert to tensor and normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load CIFAR dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV-Ri-SN8ggH",
        "outputId": "595abc5d-7cee-4038-8aa8-0e5cdc3dfb2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 78.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet model\n",
        "class AlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
        "                        padding= 'valid', activation= 'relu',\n",
        "                        input_shape= input_shape,\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(1000, activation= 'relu'))\n",
        "        self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "        self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oEzmg5DdApss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "\n",
        "# training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "image_height = 227\n",
        "image_width = 227\n",
        "# train_dir should point to the extracted CIFAR-10 directory\n",
        "train_dir = \"/content/drive/MyDrive/ACL\"\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "model = AlexNet((227, 227, 3), num_classes)\n",
        "\n",
        "# training parameters\n",
        "# train_dir = \"./data/cifar-10-python.tar.gz\"\n",
        "# valid_dir = \"./content/validation\"\n",
        "# model_dir = \"./my_model.h5\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale=1./255,\n",
        "                  rotation_range=10,\n",
        "                  width_shift_range=0.1,\n",
        "                  height_shift_range=0.1,\n",
        "                  shear_range=0.1,\n",
        "                  zoom_range=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(image_height, image_width),\n",
        "                                                    color_mode=\"rgb\",\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    seed=1,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode=\"categorical\")\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
        "                                                    target_size=(image_height, image_width),\n",
        "                                                    color_mode=\"rgb\",\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    seed=7,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode=\"categorical\"\n",
        "                                                    )\n",
        "train_num = train_generator.samples\n",
        "valid_num = valid_generator.samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "zFeFcok0AzcO",
        "outputId": "433fed57-56e4-47b6-ac1f-b9d1f19cc780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './content/validation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e3b7943a9a77>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                     class_mode=\"categorical\")\n\u001b[1;32m     41\u001b[0m \u001b[0mvalid_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m valid_generator = valid_datagen.flow_from_directory(valid_dir,\n\u001b[0m\u001b[1;32m     43\u001b[0m                                                     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                                     \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './content/validation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('./logs')\n",
        "os.mkdir('./logs/fit')\n",
        "\n",
        "log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "callback_list = [tensorboard_callback]\n",
        "\n",
        "# start training\n",
        "model.fit(train_generator,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=train_num // BATCH_SIZE,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=valid_num // BATCH_SIZE,\n",
        "                    callbacks=callback_list,\n",
        "                    verbose=0)\n",
        "model.summary()\n",
        "\n",
        "# save the whole model\n",
        "model.save(model_dir)\n",
        "\n",
        "'''\n",
        "Model: \"alex_net\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #\n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 55, 55, 96)        34944\n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0\n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656\n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0\n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120\n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488\n",
        "_________________________________________________________________\n",
        "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992\n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0\n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 9216)              0\n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 4096)              37752832\n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 4096)              16781312\n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 1000)              4097000\n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 2)                 2002\n",
        "=================================================================\n",
        "Total params: 62,380,346\n",
        "Trainable params: 62,380,346\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VfqWvzs4BqhU",
        "outputId": "61e790f7-3aa3-489d-f55d-b9b40414aea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-28bcd1848f60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.fit(train_generator,\n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDwpr_GxCfyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}